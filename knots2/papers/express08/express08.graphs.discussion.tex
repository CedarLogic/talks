\section{Discussion}

Apart from this formalization of the intuition in Kauffman's virtual
knots, we see three other benefits of this treatment of graphs in the
context of this factorization of the Meredith-Snyder encoding of
knots. 

\begin{itemize}
  \item it establishes the basis for a new language for composing graphs;
  \item it establishes the basis for the application of spatial and
    context logics to graphs;
  \item it establishes a conceptual bridge it provides between
    `static' graphs and the more dynamical systems these graphs are
    often intended to capture.
\end{itemize}

We discuss these in turn in the section below.

\subsection{Composing graphs from graphs}

As Meredith and Snyder point out in \cite{}, knot composition lines up
well with the process compositors. In a similar fashion, through the
vehicle of this encoding, an argument can be made that graphs are not
built from vertices and edges. Rather, in the same way that processes
are put together by composing processes, graphs are built by composing
graphs. This is somewhat of a departure from traditional thinking both
from a theoretical perspective and an application
perspective. Traditional graph theory texts do not emphasize an
algebraic compositional theory. This is a much more modern
perspective, and still undergoing development. Likewise, that software
tools for manipulating graphs (such as Visio or OmniGraffle or Dot) do
not take a compositional view of graphs is evinced in the interfaces
provided for manipulating them. This is invariably through nodes and
links.

\subsection{Describing graphs in logic}

Cardelli, Ghelli and Gardner have pioneered the application of various
flavors of the Hennesssy-Milner logics, especially the spatial logics,
and more recently, context logics, to reasoning about tree
structures. Here we advocate for the extension of this programme to
graphs more generally.

\subsection{Dynamic graphs}

As mentioned before, a process representing the graph encodes the
mathematical data in terms of observations to be made by poking and
prodding it. It represents a `static' structure by virtue of returning
to its original configuration after all such pokes and prods. More
precisely, note that every observation one can make of the process of
a graph must be made in terms of an observation of the process of one
of its vertices, but after every observation and response, so to
speak, a vertex process returns to its original state by making a
recursive call to its behavioral definition.

More formally, from equation \ref{vcode} it is easy to see that only
barbs at $\widehat{\textsf{src}(e)}$ or $\widehat{\textsf{trgt}(e)}$
for $e$ in the cone of $v$ will perturb $\meaningof{v}_{\pi}$. Such a
barb will cause the continuation of $\meaningof{v}_{\pi}$ to forward
the signal to $\hat{v}$ or $\widehat{\textsf{trgt}(e)}$, and then
return to the state $\meaningof{v}_{\pi}$. Returning to state
$\meaningof{v}_{\pi}$ is essential aspect of what makes this structure
`static', for even if there are any loops in the graph, causing its
encoding to continue to reduce indefinitely after a barb that feeds
into a loop, under fair scheduling of choices it will return
infinitely often to a state bisimilar to the original state composed
with the barb.

