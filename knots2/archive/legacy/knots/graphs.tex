% ------------------------------------------------------------------------
% LNCS LaTeX Paper ******************************************************
% ------------------------------------------------------------------------
% Submitted:      July 12 2005
% Final Version:  
% Accepted:       
% ------------------------------------------------------------------------
% This is a journal top-matter template file for use with AMS-LaTeX.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\documentclass{tran-l}
%\documentclass[twocolumn]{amsart}
%\documentclass[]{amsart}
\documentclass[]{llncs}
\usepackage[all,knot]{xy}

\newif\ifpdf
\ifx\pdfoutput\undefined
\pdffalse % we are not running PDFLaTeX
\else
\pdfoutput=1 % we are running PDFLaTeX
\pdftrue
\fi

\ifpdf
\usepackage[pdftex]{graphicx}
\else
\usepackage{graphicx}
\fi
%\usepackage[pdftex]{graphicx}

%\documentclass[]{entcs}
%\usepackage[]{prentcsmacro}

%\usepackage[active]{srcltx} % SRC Specials for DVI Searching
\usepackage {mathpartir}
%\usepackage {listings}
%\usepackage {array}
\usepackage{url}

% From Allen's stable.
%\usepackage{bigpage}
\usepackage{bcprules}
\usepackage{code}
\usepackage{amsfonts}
\usepackage{amstext}
\usepackage{latexsym}
\usepackage{amssymb}
%\usepackage{caption}
\usepackage{multicol}

\input{lgmHeader.tex}

\newcommand{\papertitle}{Graphs as processes: the role of persistence in dynamics}
% use static date to preserve date of actual publication
\newcommand{\paperversion}{Draft Version 0.1 - Mar 13, 2006}

\newenvironment{toc}
{
\begin{list}{}{
   \setlength{\leftmargin}{0.4in}
   \setlength{\rightmargin}{0.6in}
   \setlength{\parskip}{0pt}
 } \item }
{\end{list}}

\newenvironment{narrow}
{
\begin{list}{}{
   \setlength{\leftmargin}{0.4in}
   \setlength{\rightmargin}{0.6in}
 } \item }
{\end{list}}

\def\lastname{Meredith and Snyder}
%%% ----------------------------------------------------------------------

\begin{document}

%\begin{frontmatter}
\title{Graphs as processes: the role of persistence in dynamics}
\titlerunning{Graphs as processes}

\author{ L.G. Meredith\inst{1} \and David F. Snyder\inst{2} }
\institute{ CXO, Biosimilarity\\ 505 N72nd St, Seattle, WA 98103, USA, \\
  \email{ lgreg.meredith@gmail.com } \\
  \and Associate Professor of Mathematics\\ Dept of Mathematics\\ Texas State University\\ 601 University Drive \\ San Marcos, TX 78666 \\
  \email{ dsnyder@txstate.edu }
} 

\maketitle              % typeset the title of the contribution

%%% ----------------------------------------------------------------------

\begin{abstract}
  
  In \cite{} Meredith and Snyder exhibit an encoding of knots as
  processes with the property that knots are ambient isotopic if and
  only if their encodings as processes are weakly bisimilar. Here we
  show that this encoding factors through an encoding of graphs as
  processes. While encoding graphs as processes is by now a familiar
  idea this factorization can be seen in the light of Abramsky's
  notion of mathematical objects `extended in time' thus providing not
  only a conceptual bridge between what is static and what is dynamic,
  but also offering a basis for extending calculations on `static'
  graph-like structures to more dynamic versions. Recent use of graphs
  as vehicles for modeling various aspects of interaction in physical
  systems -- notably, using graphs to capture aspects of
  biological systems such as signaling and metabolic processes within
  a cell -- provide motivation for seeking such a conceptual bridge.

\end{abstract}

% \begin{keyword}
% concurrency, message-passing, process calculus, reflection, program logic
% \end{keyword}

%\end{frontmatter}

\section{Introduction and motivation}

In recent years, graphs have come to the fore as vehicles for modeling
various aspects of interaction in physical systems. Notably, graphs
are being used to capture aspects of biological systems such as
signaling and metabolic processes within a cell, or gene activation
processes. Of course, they also show up in a wide variety of other
models of physical systems, at one extreme, graphs form the basis of
so-called spin networks in loop quantum gravity. What these examples
have in common is that the graph is really an abstraction of the
communication topology of a (set of) processes that are, in reality,
dynamical systems, not static structures.
  
We exhibit an encoding of graphs as processes in the
$\pi$-calculus. While encoding graphs as processes is by now a
familiar idea two ideas emerge as novel in this encoding. Firstly, the
approach exhibits not only a conceptual bridge between what is static
and what is dynamic, but also offers a basis for extending
calculations on `static' graph-like structures to more dynamic
versions. Secondly, the encoding provides a vehicle by which the
notion of process equivalence extends to other structures, in such a
way that the notion of process equivalence coincides with the notion
of equivalence contemplated `natively' in the structures they model.

\subsection{Overview and summary of contributions}

In section \ref{Pinut} we give a brief review of the polyadic
$\pi$-calculus, immediately following that with a review of the graph
theoretical machinery graph needed to state and prove our main
theorem. Next, we introduce the intuitions behind the encoding,
sketching the general shape and walking through the procedure in the
case of a simple graph. We follow this with the details of the
encoding. This puts us in a position to state and prove the main
theorem, which we do in section \ref{MainThm}. In the penultimate
section we discussion some of the results following from this method
of encoding, illustrating a way to interpret graph composition as
parallel composition and sketching out some of the dynamical
interpretations of graphs. Finally, we state some conclusions and
adumbrate some directions for future research.

\section{The $\pi$-calculus in a nutshell} \label{Pinut}

This section reprises the variant of the $\pi$-calculus used to
establish the results.

\subsection{\pic}

As mentioned above, the grammar generating the set of processes may be
seen as a kind of generalized set of generators in a presentation of
an algebra via generators and relations.

\begin{grammar}
\mbox{summation} & {N} & \bc & \Sigma_{i \in I} x_i.A_i \\
\mbox{agent} & {A} & \bc & F \;| \; C \;| \; (\nu \; \vec{x})A \\
\mbox{abstraction} & {F} & \bc & (\vec{x})P \;| \; (\nu \; \vec{x})F \\
\mbox{concretion} & {C} & \bc & [\vec{x}]P \;| \; (\nu \; \vec{x})C \\
\mbox{process} & {P,Q} & \bc & N \;| \;P|Q \;| X\langle \vec{y} \rangle \;| \; (\textsf{rec} \; X(\vec{x}).P)\langle \vec{y} \rangle \;| \; (\nu \; \vec{x})P
\end{grammar} 

Note, we identify summation over an empty index set with the null
process, $\pzero$, and prefixing with a summation over a singleton
index set. We adopt vector notation, $\vec{x}$, for finite sequences
of names, $x_0,...,x_{n-1}$, and define the \emph{arity} of sequences,
$|x_0,...,x_{n-1}| = n$, extending it in a natural way to abstractions
and concretions, e.g. $|(\vec{x})P| = |\vec{x}|$.

Further, we define \emph{pseudo-application} of an abstraction to a concretion via

\begin{equation}
  (\vec{y})P \circ (\nu \vec{v})[\vec{z}]Q \triangleq (\nu \vec{v})(P\{\vec{z}/\vec{y}\} | Q)
\end{equation}

provided that $\vec{y} \cap \vec{v} = \emptyset$ and $|\vec{y}| = |\vec{z}|$.

We also adopt the following standard abbreviations.

\begin{eqnarray}
  x?(\vec{y}).P & \triangleq & x.(\vec{y})P \\
  x!(\vec{y}).P & \triangleq & x.[\vec{y}]P
\end{eqnarray}

In a somewhat roundabout manner we also use 

\begin{equation}
  X(\vec{y}) := P \triangleq (\vec{y})(\textsf{rec} \; X(\vec{x}).P)\langle \vec{y} \rangle
\end{equation}

\paragraph{Free and bound occurrences}

The syntax has been so chosen that every occurrence of a name between
round braces (as in $(x)P$, or $(\nu \; x)P$) is a binding
occurrence. The free names of a process, $P$, written $\freenames{P}$, are
calculated accordingly.

\subsection{Structural congruence}

In keeping with the generalized generators and relations view, the
structural congruence can be seen as the set of relations over the
`free' algebra generated by the grammar above.

\begin{definition}
  The {\em structural congruence}, $\equiv$, between processes is the
  least congruence closed with respect to alpha-renaming, satisfying
  the abelian monoid laws (associativity, commutativity and $\pzero$
  as identity) for parallel composition as well as summation, and the
  following axioms:
\begin{enumerate}
\item the scope laws:
\begin{eqnarray}
 (\nu \; x)\pzero  & \equiv & \pzero, \nonumber\\
 (\nu \; x)(\nu \; x)P & \equiv & (\nu \; x)P, \nonumber\\
 (\nu \; x)(\nu \; y)P & \equiv & (\nu \; y)(\nu \; x)P, \nonumber\\
 P | (\nu \; x)Q & \equiv & (\nu \; x)(P|Q), \; \mbox{\textit{if} }x \not\in \freenames{P} \nonumber
\end{eqnarray}
\item
the recursion law:
\begin{eqnarray}
  (\textsf{rec} \; X(\vec{x}).P)\langle \vec{y} \rangle \equiv P\{\vec{y}/\vec{x}\}\{(\textsf{rec} \; X(\vec{x}).P)/X\} \nonumber
\end{eqnarray}
\end{enumerate}
\end{definition}

\subsection{Operational semantics} 

Finally, we introduce of the computational dynamics through the
reduction relation, $\red$.

\begin{mathpar}
  \inferrule* [Right=Comm] { |F| = |C| } { x.F \juxtap x.C \red F \circ C }
  \and \\
  \inferrule* [Left=Par] {{P} \red {P}'} {{{P} | {Q}} \red {{P}' | {Q}}}
  \and
  \inferrule* [Right=New] {{P} \red {P}'} {{\newp{{x}}{{P}}} \red {\newp{{x}}{{P}'}}}
  \and \\
  \inferrule* [Right=Equiv]{{{P} \scong {P}'} \andalso {{P}' \red {Q}'} \andalso {{Q}' \scong {Q}}}{{P} \red {Q}}
\end{mathpar}

We write $\wred$ for $\red^*$.

\subsection{Bisimulation}

The computational dynamics gives rise to another kind of equivalence,
the equivalence of computational behavior. As previously mentioned
this is typically captured via some form of bisimulation. The notion
we use in this paper is weak barbed bisimulation \cite{milner91polyadicpi}.

\begin{definition}
  An agent, $B$, occurs \emph{unguarded} in $A$ if it has an occurence
  in $A$ not guarded by a prefix $x$. A process $P$ is observable at
  $x$, written here $P \downarrow x$, if some agent $x.A$ occurs
  unguarded in $P$. We write $P \Downarrow x$ if there is $Q$ such
  that $P \wred Q$ and $Q \downarrow x$.
\end{definition}

\begin{definition}
%\label{def.bbisim}
A \emph{barbed bisimulation} is a symmetric binary relation 
${\mathcal S}$ between agents such that $P\rel{S}Q$ implies:
\begin{enumerate}
\item If $P \red P'$ then $Q \wred Q'$ and $P'\rel{S} Q'$.
\item If $P\downarrow x$, then $Q\Downarrow x$.
\end{enumerate}
$P$ is barbed bisimilar to $Q$, written
$P \simeq Q$, if $P \rel{S} Q$ for some barbed bisimulation ${\mathcal S}$.
\end{definition}

One of the principal advantages of this framework is the co-algebraic
proof method for establishing bisimilarity between two processes:
exhibit a bisimulation \cite{DBLP:conf/lics/Sangiorgi04}.

\section{Graphs}

\begin{definition}
  A \emph{graph} consists of the following data $(V,E,\textsf{src},\textsf{trgt})$:
  \begin{enumerate}
    \item a set, $V$, of \emph{vertices} (alternately, \emph{nodes});
    \item a set, $E$, of \emph{edges} (alternately, \emph{arrows} or \emph{links});
    \item a map, $\textsf{src}:E \to V$, determining the \emph{source} of an edge;
    \item a map, $\textsf{trgt}:E \to V$, determining the \emph{target} of an edge;
  \end{enumerate}
\end{definition}

This definition is general enough to capture both directed and
undirected graphs. In particular, nothing in the definition dictates
that an edge is oriented from source to target. Rather, each edge,
$e$, has two endpoints, source and target, accessed by the functions,
$\textsf{src}$, and $\textsf{trgt}$, respectively. And, speaking of
accessing, we will avail ourselves of standard `accessor' function
notation. Thus, if $G = (V,E,\textsf{src},\textsf{trgt})$, then $V(G)
= V$ and $E(G) = E$, etc.

\begin{example} \label{seqex}
  \begin{enumerate}
  \item The \emph{discrete graph}, $G(n)$, is given by
  $(\{0,...,n-1\},\emptyset,\bot,\bot)$ where $\bot$ is the function
  with empty domain.

  \item A \emph{chain}, $C(n)$, is given by 
  \begin{enumerate}
    \item $V(C(n)) = \{0,...,n-1\}$;
    \item $E(C(n)) = \{e_0,...,e_{n-2}\}$;
    \item $\textsf{src}(e_i)=e_{i-1}, 0 \leq i \leq n-2$;
    \item $\textsf{trgt}(e_i)=e_{i+1},0 \leq i \leq n-2$.
  \end{enumerate}

  \item A \emph{Loop}, $L(n)$, is constructed from a chain,
  $C(n)$, by adding an edge, $e_{n-1}$ with
  $\textsf{src}(e_{n-1})=e_{n-2}$ and $\textsf{trgt}(e_{n-1})=e_{0}$.
  \end{enumerate}
\end{example}

\begin{example} \label{knotex}
  A \emph{knot} is an embedding, $K : S^0 \to \Real^3$, of the circle
  into 3-space. A \emph{knot diagram} is a projection of a knot onto
  the plane such that every crossing is of the form .... A \emph{knot
    shadow} is a graph derived from a knot diagram by associating
  vertices to crossings and edges between connected crossings. Note
  that a knot shadow is always a tetravalent graph, i.e. for any
  vertex, $v$, the cardinality of the cone of $v$ is $|\textsf{e}(v)|
  = 4$.
\end{example}

\begin{example} \label{chemex}
  \begin{eqnarray}
    E + S \rightleftharpoons ES \rightarrow E + P
  \end{eqnarray}
\end{example}

\begin{definition}
  A \emph{subgraph}, $H$, of a graph, $G$, is a graph such that
  \begin{enumerate}
     \item $V(H) \subseteq V(G)$;
     \item $E(H) \subseteq E(G)$;
     \item $\textsf{src}(H) = \textsf{src}(G) \backslash E(H)$;
     \item $\textsf{trgt}(H) = \textsf{trgt}(G) \backslash E(H)$;
  \end{enumerate}
  More generally, given graphs, $G, H$, a graph \emph{homomorphism},
  $m: G \to H$, from $G$ to $H$ is a pair of functions, $m_V : V(G)
  \to V(H)$, $m_E : E(G) \to E(H)$ such that $\textsf{src}(m_E(e)) =
  m_V(\textsf{src}(e))$ and $\textsf{trgt}(m_E(e)) =
  m_V(\textsf{trgt}(e))$. And a graph \emph{isomorphism} is a graph
  homomorphism in which the vertex and edge maps are bijections.
\end{definition}

As usual, we overload $\subseteq$ for the subgraph relation. Thus,
$G(n) \subseteq C(n) \subseteq L(n)$ holds for the examples above. We
write $G \sim H$ when there exists a graph isomorphism between $G$ and
$H$.

\begin{definition}
  A \emph{path}, $p$, in graph, $G$, is an ordered collection of
  edges, $p = (e_0, ..., e_N)$, such that $\textsf{src}(e_i) =
  \textsf{trgt}(e_{i-1})$. We use the notation $p[i]$ to access the
  $i$th edge in the path, $p$, and $|p|$ to denote the length of the
  path. Like an edge, a path, $p$, has a source, $\textsf{src}(p)$,
  and a target, $\textsf{trgt}(p)$, calculated as $\textsf{src}(p) =
  \textsf{src}(p[0])$, and $\textsf{trgt}(p) =
  \textsf{trgt}(p[|p|-1])$.
\end{definition}

\begin{definition}
  A \emph{connected component}, $C$, of a graph, $G$, is a subgraph of
  $G$ such that there is a path between every distinct pair of
  vertices. That is, for all $v_0, v_1$ such that $v_0 \neq v_1$ there
  exists a $p$ in $C$ such that either $\textsf{src}(p) = v_0$ and
  $\textsf{trgt}(p) = v_1$ or $\textsf{src}(p) = v_1$ and
  $\textsf{trgt}(p) = v_0$.
\end{definition}

\begin{remark}
  Note that while chains and loops have a single connected component
  the discrete graph $G(n)$ enjoys $n$ connected components.
\end{remark}

\begin{definition}
  The \emph{slice} of a vertex, $v$, in a graph, $G$, is given by
  \begin{equation}
    \textsf{slice}_{G}(v) \triangleq \{ e \; | \; \textsf{src}(e) = v \}
  \end{equation}
  and the \emph{co-slice} is given by
  \begin{equation}
    \textsf{co-slice}_{G}(v) \triangleq \{ e \; | \; \textsf{trgt}(e) = v \}
  \end{equation}
  and the \emph{cone} is given by $\textsf{e}(v) \triangleq \textsf{slice}_{G}(v) \cup \textsf{co-slice}_{G}(v)$.
\end{definition}

As usual the subscript, $G$, will be dropped when context minimizes
the risk of confusion.

\subsection{The general encoding}

Given a graph, $G$, a pair of injective maps,
$\widehat{\cdot},\cdot^{\circ}:V(G) \hookrightarrow \mathcal{N}$, satisfying
$\widehat{V(G)} \cap V(G)^{\circ} = \emptyset$, we encode $G$ by %$\meaningof{G}_{\pi}^H(V(G),\emptyset)$ where

% \begin{eqnarray}  
%   %\lefteqn{\meaningof{G}_{\pi}^H(V,E) \triangleq} % \nonumber \\
%   \meaningof{G}_{\pi}^H(V,E) \triangleq
%   % & & \mbox{}
%   \textsf{let} \; v \uplus V' \; \textsf{=} \; V \; \textsf{in} %\nonumber \\
%   % & & \mbox{}
%   \meaningof{v}_{\pi}(E) | \meaningof{G}_{\pi}^H(V',E \cup cone(v))
% \end{eqnarray}

% and

\begin{eqnarray}
  \meaningof{G}_{\pi} & \triangleq & \Pi_{v \in V(G)}\meaningof{v}_{\pi} \\
  \meaningof{v}_{\pi} & \triangleq & \Sigma_{e \in \textsf{slice(v)}} \hat{v}(s).\widehat{\textsf{trgt}(e)}[s].\meaningof{v}_{\pi} + (\nu \; t)v^{\circ}(s).s[t]
\end{eqnarray}

\begin{remark}
  An intuitively appealing encoding would, for each vertex, record its
  participation as the endpoint of an edge as potential
  interaction. Discrete graphs, however, have vertices that are
  distinguishable \emph{despite} the absence of any edge
  structure. Thus, the encoding must also accomodate this additional
  capacity for distinguishing vertices as additional possible behavior
  at each process representing a vertex. This fact is methodologically
  noteworthy: if the mathematical data makes exploitable distinctions
  a faithful process representation must reflect these distinctions as
  distinguishable behavior. Put another way, the world-view operative
  in process calculi dictates that any difference that makes a
  difference must show up as a distinct way of kicking or prodding
  some process.   
\end{remark}

On the other hand, it is easy to see that

\begin{lemma}
  If $G$ is such that for all $v \in V(G), \textsf{e}(v) \neq
  \emptyset$, then for any distinct $v_0, v_1 \in V(G)$ $(\nu \;
  v_0^{\circ})\meaningof{v_0}_{\pi} \not\simeq (\nu \;
  v_1^{\circ})\meaningof{v_1}_{\pi}$.
\end{lemma}

%\begin{proof}
That is, in every graph in which every vertex participates as the
endpoint of at least one edge, then even if we hide behavior at
$v_i^{\circ}$, the processes $(\nu \;
v_i^{\circ})\meaningof{v_i}_{\pi}$ are distinct for distinct nodes,
$v_0, v_1$. For, in the worst case, when the cone of $v_0$ equals the
cone of $v_1$ there can never be an edge in which they are
simultaneously the source or simultaneously the target. Hence, there
is always some distinguishing behavior. In fact, the adventurous
reader is encouraged to write down the distinguishing Hennessy-Milner
formula.
%\end{proof}

This fact allows us to employ a simpler encoding for graphs of this type, i.e.

\begin{eqnarray}\label{vcode}
  \meaningof{v}_{\pi} & \triangleq & \Sigma_{e \in \textsf{slice(v)}} \hat{v}(s).\widehat{\textsf{trgt}(e)}(s).\meaningof{v}_{\pi}
\end{eqnarray}

In a similar vein we have

\begin{theorem}\label{grapheqthm}
  $\meaningof{G}_{\pi} \simeq \meaningof{H}_{\pi} \iff  G \sim H$.
\end{theorem}

\begin{proof}
  By construction.
\end{proof}

\begin{remark}
  We observe that there is an dual encoding given by
  \begin{eqnarray}
  \meaningof{G}_{\pi}^{\bullet} & \triangleq & \Pi_{v \in V(G)}\meaningof{v}_{\pi}^{\bullet} \\
  \meaningof{v}_{\pi}^{\bullet} & \triangleq & \Sigma_{e \in \textsf{co-slice(v)}} \widehat{\textsf{src}(e)}(s).\hat{v}[s].\meaningof{v}_{\pi}^{\bullet} + (\nu \; t)v^{\circ}(s).s[t]
\end{eqnarray}
\end{remark}

\subsubsection{Examples}

\begin{example}
  \begin{enumerate}
    \item $\meaningof{G(n)}_{\pi} = \Pi_{i=0}^{n-1}(\nu \; t)i^{\circ}(s).s[t]$

    \item $\meaningof{C(n)}_{\pi} = \Pi_{i=0}^{n-2}\hat{i}(s).\widehat{i+1}[s]$

    \item $\meaningof{L(n)}_{\pi} = \Pi_{i=0}^{n-1}\hat{i}(s).\widehat{(i+1 \; mod \; n)}[s]$
  \end{enumerate}
\end{example}

\section{Factoring knots as processes through graphs as processes} \label{MainThm}

Two observations come together to provide the main theorem. The first
is an entirely technical observation that the encoding of the graph in
example \ref{knotex} can be refactored as

\begin{equation}
  \meaningof{K}_{\pi} = \Pi_{i = 0}^{n-1} \meaningof{C(i)}_{\pi}(v_{\omega(i,0)},...,v_{\omega(i,3)})
\end{equation}

where $n$ is the crossing number of $K$, and $\omega: n \times 4 \to
2n$, gives the index into the list of ports, $v_0 ... v_{2n-1}$ used
to wire the crossing vertices together in a manner consistent with the
chosen knot diagram of $K$.

The second and more significant observation is that the process
associated with
$\meaningof{C(i)}_{\pi}(v_{\omega(i,0)},...,v_{\omega(i,3)})$ may be
replaced by a process that \emph{simulates} it. In some real sense we
are treating the process associated with the vertex of a knot shadow
as the minimal specification of the \emph{interface} of the crossing
behavior, treating what goes on inside the crossing as a black
box. This notion is entirely consistent with and in some sense
strengthens Kauffman's idea of virtual knots by formalizing the sense
in which they may be virtualized.

The process we substitute for this minimal specification codes what it
means for a wire to cross over or under. We interpret this as a
synchronization. Thus, a crossing ``circuit'' of the $i$-th crossing
of a knot, $K$, is a process,
$\meaningof{C(i)}_{\pi}(x_0,x_1,y_0,y_1,u)$, parameterized in $4+1$
ports corresponding to the in-coming and out-going arcs between each
crossing together with an \emph{additional} port representing the
synchronizer for letting signals `cross over' in the gates. The wire
crossing over is allowed to transmit the signal without waiting while
the under-crossing wire must wait for an additional input on a
synchronization channel. To alert the under-crossing wire that it may
now proceed, the over-crossing wire must fire off an output. Thus,
setting $(\vec{a}) = (x_0,x_1,y_0,y_1,u)$ a crossing circuit is coded
as the following process.

\begin{eqnarray}
  C(\vec{a}) & := & x_1?(s).y_0!(s).(C(\vec{a})|u!) + y_0?(s).x_1!(s).(C(\vec{a})|u!) \nonumber \\
  & & + x_0?(s).u?.y_1!(s).(C(\vec{a})) + y_1?(s).u?.x_0!(s).(C(\vec{a})) 
\end{eqnarray}

Recognizing that the maps from vertices to names are really a
convenient way of parameterizing the encoding in a set of names
corresponding to the vertices, the encoding of a knot, $K$, becomes

\begin{equation}
  \meaningof{K}_{\pi} = (v_0 ... v_{2n-1}) \Pi_{i = 0}^{n-1} (\nu \; u)\meaningof{C(i)}_{\pi}(v_{\omega(i,0)},...,v_{\omega(i,3)},u)
\end{equation}

Meredith and Snyder have already shown that this encoding enjoys the
property that two knots are ambient isotopic iff their encodings as
processes are weakly bisimilar. What we show here as that this
correspondence factors through the equivalence of graphs noted in
theorem \ref{grapheqthm}. In fact, this result follows immediately
from the choice of $\meaningof{C(i)}_{\pi}(x_0,x_1,y_0,y_1,u)$ to
simulate
$\meaningof{C(i)}_{\pi}(v_{\omega(i,0)},...,v_{\omega(i,3)})$.

\section{Discussion}

Apart from this formalization of the intuition in Kauffman's virtual
knots, we see three other benefits of this treatment of graphs in the
context of this factorization of the Meredith-Snyder encoding of
knots. 

\begin{itemize}
  \item it establishes the basis for a new language for composing graphs;
  \item it establishes the basis for the application of spatial and
    context logics to graphs;
  \item it establishes a conceptual bridge it provides between
    `static' graphs and the more dynamical systems these graphs are
    often intended to capture.
\end{itemize}

We discuss these in turn in the section below.

\subsection{Composing graphs from graphs}

As Meredith and Snyder point out in \cite{}, knot composition lines up
well with the process compositors. In a similar fashion, through the
vehicle of this encoding, an argument can be made that graphs are not
built from vertices and edges. Rather, in the same way that processes
are put together by composing processes, graphs are built by composing
graphs. This is somewhat of a departure from traditional thinking both
from a theoretical perspective and an application
perspective. Traditional graph theory texts do not emphasize an
algebraic compositional theory. This is a much more modern
perspective, and still undergoing development. Likewise, that software
tools for manipulating graphs (such as Visio or OmniGraffle or Dot) do
not take a compositional view of graphs is evinced in the interfaces
provided for manipulating them. This is invariably through nodes and
links.

\subsection{Describing graphs in logic}

Cardelli, Ghelli and Gardner have pioneered the application of various
flavors of the Hennesssy-Milner logics, especially the spatial logics,
and more recently, context logics, to reasoning about tree
structures. Here we advocate for the extension of this programme to
graphs more generally.

\subsection{Dynamic graphs}

As mentioned before, a process representing the graph encodes the
mathematical data in terms of observations to be made by poking and
prodding it. It represents a `static' structure by virtue of returning
to its original configuration after all such pokes and prods. More
precisely, note that every observation one can make of the process of
a graph must be made in terms of an observation of the process of one
of its vertices, but after every observation and response, so to
speak, a vertex process returns to its original state by making a
recursive call to its behavioral definition.

More formally, from equation \ref{vcode} it is easy to see that only
barbs at $\widehat{\textsf{src}(e)}$ or $\widehat{\textsf{trgt}(e)}$
for $e$ in the cone of $v$ will perturb $\meaningof{v}_{\pi}$. Such a
barb will cause the continuation of $\meaningof{v}_{\pi}$ to forward
the signal to $\hat{v}$ or $\widehat{\textsf{trgt}(e)}$, and then
return to the state $\meaningof{v}_{\pi}$. Returning to state
$\meaningof{v}_{\pi}$ is essential aspect of what makes this structure
`static', for even if there are any loops in the graph, causing its
encoding to continue to reduce indefinitely after a barb that feeds
into a loop, under fair scheduling of choices it will return
infinitely often to a state bisimilar to the original state composed
with the barb.

\section{Conclusions and future work}

TBD


\paragraph{Acknowledgments.}
The author wishes to acknowledge his longstanding debt to Samson
Abramksy for making so accessible his foundational insights into the
Curry-Howard isomorphism.

% ------------------------------------------------------------------------
%GATHER{Xbib.bib}   % For Gather Purpose Only
%GATHER{Paper.bbl}  % For Gather Purpose Only
\bibliographystyle{plain}
\bibliography{graphs}

% ------------------------------------------------------------------------

% ------------------------------------------------------------------------

\end{document}
% ------------------------------------------------------------------------
